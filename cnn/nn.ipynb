{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ecg_route = \"C:/Users/leo/Desktop/machine learning/project/wfdb-python-master/psr-20ms\"\n",
    "ecg_route2 = \"C:/Users/leo/Desktop/machine learning/project/wfdb-python-master/psr-20ms/\"\n",
    "expand_route = \"C:/Users/leo/Desktop/machine learning/project/wfdb-python-master/psr-20ms-expand\"\n",
    "expand_route2 = \"C:/Users/leo/Desktop/machine learning/project/wfdb-python-master/psr-20ms-expand/\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#binary classfication\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_x = np.zeros((2000,400,400,3),int)\n",
    "train_y = np.zeros((2000),int)\n",
    "test_x = np.zeros((300,400,400,3),int)\n",
    "test_y = np.zeros((300),int)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#binary classfication\n",
    "from sklearn.externals._pilutil import imread\n",
    "label_route=\"C:/Users/leo/Desktop/machine learning/project/wfdb-python-master/training2017/REFERENCE-original.csv\"\n",
    "data=pd.read_csv(label_route)\n",
    "class_name=['N','A']\n",
    "count_test=0\n",
    "count_train=0\n",
    "count_train_n=0\n",
    "count_train_a=0\n",
    "count_test_n=0\n",
    "count_test_a=0\n",
    "val=0\n",
    "list_test=[] \n",
    "for root, dirs, files in os.walk(ecg_route):\n",
    "    random.shuffle(files)\n",
    "    for file in files:\n",
    "        name=file[1:6]\n",
    "        num = int(name)\n",
    "        I = imread(ecg_route2+file)\n",
    "        #n = random.random()\n",
    "        #if count<1200:\n",
    "        if data['type'][num-1]=='N' and count_train_n<1000:\n",
    "            train_x[count_train] = I\n",
    "            train_y[count_train] = class_name.index(data['type'][num-1])\n",
    "            count_train_n+=1\n",
    "            count_train+=1\n",
    "            #count += 1\n",
    "        elif data['type'][num-1]=='N' and count_train_n>=1000 and count_test_n<150:\n",
    "            test_x[count_test] = I\n",
    "            test_y[count_test] = class_name.index(data['type'][num-1])\n",
    "            count_test_n+=1\n",
    "            count_test+=1   \n",
    "        elif data['type'][num-1]=='A' and count_test_a<150:\n",
    "            test_x[count_test] = I\n",
    "            test_y[count_test] = class_name.index(data['type'][num-1])\n",
    "            count_test_a+=1\n",
    "            count_test += 1\n",
    "            list_test.append(num)\n",
    "        elif data['type'][num-1]=='A' and count_test_a>=150 and count_train_a<1000:\n",
    "            if num not in list_test:\n",
    "                train_x[count_train] = I\n",
    "                train_y[count_train] = class_name.index(data['type'][num-1])\n",
    "                count_train_a+=1\n",
    "                count_train += 1 \n",
    "\n",
    "for root, dirs, files in os.walk(expand_route):\n",
    "    random.shuffle(files)\n",
    "    for file in files:\n",
    "        name=file[1:6]\n",
    "        num = int(name)\n",
    "        I = imread(expand_route2+file)\n",
    "        if data['type'][num-1]=='A' and count_train_a<1000:\n",
    "            if num not in list_test:\n",
    "                train_x[count_train] = I\n",
    "                train_y[count_train] = class_name.index(data['type'][num-1])\n",
    "                count_train_a+=1\n",
    "                count_train+=1 \n",
    "        elif data['type'][num-1]=='A' and count_train_a>=1000 and count_test_a<150:\n",
    "            test_x[count_test] = I\n",
    "            test_y[count_test] = class_name.index(data['type'][num-1])\n",
    "            count_test_a+=1\n",
    "            count_test += 1\n",
    "                \n",
    "classes = np.unique(train_y)\n",
    "nClasses = len(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_results(nn_model_train): # plot performance over the training epochs\n",
    "    accuracy     = nn_model_train.history['accuracy']\n",
    "    val_accuracy = nn_model_train.history['val_accuracy']\n",
    "    loss         = nn_model_train.history['loss']\n",
    "    val_loss     = nn_model_train.history['val_loss']\n",
    "    epochs       = range(len(accuracy))\n",
    "    nb_epochs    = len(epochs)\n",
    "\n",
    "    f2 = plt.figure(2)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis((0,nb_epochs,0,1.2))\n",
    "    plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis((0,nb_epochs,0,1.2))\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.draw()\n",
    "    plt.pause(0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def predict_and_visualize_results(model, input_X, output_Y):\n",
    "    predicted_classes = model.predict(input_X) # Computes for every image in the test dataset\n",
    "                                              # a probability distribution over the 10 categories\n",
    "    predicted_classes = np.argmax(np.round(predicted_classes),axis=1) # Choose the prediction with the highest probability\n",
    "    correctIndex = np.where(predicted_classes==output_Y)[0]\n",
    "    incorrectIndex = np.where(predicted_classes!=output_Y)[0]\n",
    "    print(\"Found %d correct labels\" % len(correctIndex))\n",
    "    print(\"Found %d incorrect labels\" % len(incorrectIndex))\n",
    "    cm = confusion_matrix(output_Y,predicted_classes)\n",
    "    print(cm)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imgPixelDim = 400 # image pixel dimension\n",
    "\n",
    "## -- Reshape the images to match the NN input format  -- ##\n",
    "train_x = train_x.reshape(-1, imgPixelDim, imgPixelDim, 3) # nb of images: -1 for automatically assigned; pixels: imgPixelDim x imgPixelDim ; nb of channels: 1 for grey scale, 3 for RGB\n",
    "test_x = test_x.reshape( -1, imgPixelDim, imgPixelDim, 3)\n",
    "\n",
    "## -- Convert data type from int8 to float32 -- ##\n",
    "train_x = train_x.astype('float32')\n",
    "test_x = test_x.astype('float32')\n",
    "\n",
    "## -- Normalize the dtata: rescale the pixel values in range 0 - 1 inclusive for training purposes -- ##\n",
    "train_x = train_x / 255.\n",
    "test_x = test_x / 255.\n",
    "\n",
    "## -- Change the labels from categorical to one-hot encoding -- ##\n",
    "# Example: image label 7 becomes [0 0 0 0 0 0 0 1 0] ; The output neurons of the NN will be trained to match the one_hot encoded array\n",
    "train_y_one_hot = to_categorical(train_y)\n",
    "test_y_one_hot  = to_categorical(test_y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label             :', train_y[0])\n",
    "print('After conversion to one-hot encoded:', train_y_one_hot[0])\n",
    "\n",
    "## -- Split the trainAndVal data into training dataset and validation dataset -- ##\n",
    "# The moodel is trained over the training dataset\n",
    "# The validation dataset is used to monitor when the model starts overfitting on the training dataset\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_x, train_y_one_hot, test_size=0.2, random_state=13)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "#------------------------------------ PROBLEM ------------------------------------\n",
    "#---------------------------------------------------------------------------------\n",
    "if True:\n",
    "    #------------------------------Hyper Parameters-----------------------------------\n",
    "    batch_size  = 6 # how many images with their corresponding cotegories to use per\n",
    "    # per NN weights update step\n",
    "    epochs      = 5  # how many times to loop over the entire training dataset\n",
    "    # example: for a batch_size=64 and training dataset size of 48000\n",
    "    # then each epoch will consist of 48000/64=750 updates of the network weights\n",
    "    learning_rate = 0.00096\n",
    "\n",
    "    model = Sequential()\n",
    "    # Shapes (None, 3) and (None, 200, 200, 2) are incompatible\n",
    "    #------------------------------------Architecture---------------------------------\n",
    "    model.add(Conv2D(10, kernel_size=(3, 3),activation='relu',input_shape=(400, 400, 3),padding='same'))\n",
    "    model.add(Conv2D(10, kernel_size=(3, 3), activation='relu', input_shape=(400, 400, 3), padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2),padding='same'))\n",
    "\n",
    "    model.add(Conv2D(40, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(Conv2D(40, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    # ---------------------------------------------------------------------------------\n",
    "\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    #------------------------------Optimizer-----------------------------------\n",
    "    opt = keras.optimizers.RMSprop(lr=learning_rate)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])  # Classification accuracy is the number of correct predictions made divided by the\n",
    "                                "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "#---------------------------------- PROBLEM ---- ---------------------------------\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "############################################################\n",
    "## -- Test the performmance of the untrained model over the test dataset -- ##\n",
    "predicted_classes = model.predict(test_x) # Computes for every image in the test dataset\n",
    "                                                  # a probability distribution over the 10 categories\n",
    "predicted_classes = np.argmax(np.round(predicted_classes),axis=1) # Choose the prediction with the highest probability\n",
    "\n",
    "correctIndex = np.where(predicted_classes==test_y)[0]\n",
    "incorrectIndex = np.where(predicted_classes!=test_y)[0]\n",
    "print(\"Found %d correct labels using the untrained model\" % len(correctIndex))\n",
    "print(\"Found %d incorrect labels using the untrained model\" % len(incorrectIndex))\n",
    "\n",
    "## -- Train the Neural Network -- ##\n",
    "start_time = time.time()\n",
    "fashion_train_dropout = model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))\n",
    "trainTime = (time.time() - start_time)\n",
    "print('Training time = {}'.format(trainTime))\n",
    "\n",
    "## -- Test the performmance of the trained model over the test dataset -- ##\n",
    "test_eval = model.evaluate(test_x, test_y_one_hot, verbose=0)\n",
    "print('Test loss:', test_eval[0])      # this is the categorical_crossentropy\n",
    "print('Test accuracy:', test_eval[1])  # the accuracy evaluated by the model during training and testing\n",
    "\n",
    "show_results(fashion_train_dropout)\n",
    "\n",
    "predict_and_visualize_results(model, test_x, test_y)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}